{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a13c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m:\\Project\\iot_research\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import optuna\n",
    "\n",
    "from database.query import fetch_all, load_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_all()\n",
    "df = df.drop(\"id\", axis=1)\n",
    "df.columns = [str(c) for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df[\"days_since_planting\"] = (df[\"timestamp\"] - df.groupby(\"plant_id\")[\"timestamp\"].transform(\"min\")).dt.days\n",
    "df[\"delta_soil_moisture\"] = df.groupby(\"plant_id\")[\"soil_moisture\"].diff().fillna(0)\n",
    "df[\"delta_chlorophyll\"] = df.groupby(\"plant_id\")[\"chlorophyll_content\"].diff().fillna(0)\n",
    "\n",
    "# Rolling statistics (window=3)\n",
    "for col in ['soil_moisture', 'chlorophyll_content', 'ambient_temperature']:\n",
    "    df[f'{col}_rolling_mean_3'] = df.groupby('plant_id')[col].transform(lambda x: x.rolling(3, min_periods=1).mean()).fillna(0)\n",
    "    df[f'{col}_rolling_std_3'] = df.groupby('plant_id')[col].transform(lambda x: x.rolling(3, min_periods=1).std()).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f932ddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5ea93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "df[\"plant_health_status\"] = le.fit_transform(df[\"plant_health_status\"])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "features = df.drop(columns=['timestamp', 'plant_id', 'plant_health_status']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbd3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=2503)\n",
    "train_idx, test_idx = next(gss.split(df, df['plant_health_status'], groups=df['plant_id']))\n",
    "\n",
    "train = df.iloc[train_idx].copy()\n",
    "test = df.iloc[test_idx].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train[features] = scaler.fit_transform(train[features])\n",
    "test[features] = scaler.transform(test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4a9f0",
   "metadata": {},
   "source": [
    "# Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, features, target, window_size):\n",
    "    X, y, groups = [], [], []\n",
    "\n",
    "    for plant_id, plant_df in df.groupby(\"plant_id\"):\n",
    "        plant_df = plant_df.sort_values(\"timestamp\")\n",
    "        values = plant_df[features].values\n",
    "        labels = plant_df[target].values\n",
    "\n",
    "        for i in range(len(plant_df) - window_size):\n",
    "            X.append(values[i:i+window_size])\n",
    "            y.append(labels[i+window_size])\n",
    "            groups.append(plant_id)\n",
    "\n",
    "    return np.array(X), np.array(y), np.array(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0623757",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalCNN(nn.Module):\n",
    "    def __init__(self, n_features, window_size, num_classes, n_filters, kernel_size, dropout):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_features, n_filters, kernel_size)\n",
    "        self.conv2 = nn.Conv1d(n_filters, n_filters, kernel_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear((window_size - 2*(kernel_size-1)) * n_filters, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.flatten(1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c05f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    window_size = trial.suggest_int(\"window_size\", 3, 10)\n",
    "    n_filters = trial.suggest_int(\"n_filters\", 16, 64)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 2, 4)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    X, y, groups = create_sequences(\n",
    "        train, features, \"plant_health_status\", window_size\n",
    "    )\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_idx, val_idx in gkf.split(X, y, groups):\n",
    "        model = TemporalCNN(\n",
    "            n_features=len(features),\n",
    "            window_size=window_size,\n",
    "            num_classes=num_classes,\n",
    "            n_filters=n_filters,\n",
    "            kernel_size=kernel_size,\n",
    "            dropout=dropout\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        X_train = torch.tensor(X[train_idx], dtype=torch.float32).to(device)\n",
    "        y_train = torch.tensor(y[train_idx], dtype=torch.long).to(device)\n",
    "        X_val = torch.tensor(X[val_idx], dtype=torch.float32).to(device)\n",
    "        y_val = torch.tensor(y[val_idx], dtype=torch.long).to(device)\n",
    "\n",
    "        for _ in range(20):\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(X_train), y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        preds = torch.argmax(model(X_val), dim=1)\n",
    "        f1_scores.append(\n",
    "            f1_score(y_val.cpu(), preds.cpu(), average=\"macro\")\n",
    "        )\n",
    "\n",
    "    return 1 - np.mean(f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b86a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec202ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "print(\"Best Hyperparameters:\", best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "seq_len = best_params['seq_len']\n",
    "final_dataset = PlantDataset(train, features, 'plant_health_status', seq_len=seq_len)\n",
    "final_loader = DataLoader(final_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "\n",
    "final_model = NeuralNet(input_dim=len(features), hidden_dim=best_params['hidden_dim'], \n",
    "                      num_layers=best_params['num_layers'], num_classes=num_classes, seq_len=seq_len)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=best_params['lr'])\n",
    "\n",
    "for epoch in range(50):\n",
    "    final_model.train()\n",
    "    for X_batch, y_batch in final_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PlantDataset(test, features, 'plant_health_status', seq_len=seq_len)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'])\n",
    "\n",
    "final_model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = final_model(X_batch)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580365bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(all_labels, all_preds, target_names=le.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
